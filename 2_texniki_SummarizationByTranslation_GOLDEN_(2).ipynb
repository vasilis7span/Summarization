{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[sentencepiece]\n",
        "from transformers import pipeline\n",
        "summarizer = pipeline(\"summarization\", min_length=5, max_length=20, model=\"sshleifer/distilbart-cnn-6-6\")\n",
        "translator = pipeline(\"translation_grk_to_en\", model='Helsinki-NLP/opus-mt-grk-en')\n",
        "retranslator = pipeline(\"translation_en_to_el\", model='Helsinki-NLP/opus-mt-en-el')"
      ],
      "metadata": {
        "id": "z2FTJR1sqW1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score"
      ],
      "metadata": {
        "id": "HsA10vf0eo7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\"summarization\", min_length=5, max_length=50, model=\"sshleifer/distilbart-cnn-6-6\")"
      ],
      "metadata": {
        "id": "hJiB28Zsbo3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder='/content/drive/My Drive/multilingMss2015Training/'\n",
        "!ls '/content/drive/My Drive/multilingMss2015Training/'\n",
        "\n",
        "import os\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG9blaa5UiIE",
        "outputId": "4adf24ca-25a8-441e-ff88-59202a0ac52a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "announcement.txt  body\tsummary  target-length\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_strings_within_limit(strings, max_length=1000):\n",
        "    result = []\n",
        "    current_string = \"\"\n",
        "\n",
        "    for string in strings:\n",
        "        if len(string) <= max_length:\n",
        "            # If the current string plus the new string is within the limit, concatenate\n",
        "            if len(current_string) + len(string) <= max_length:\n",
        "                current_string += string\n",
        "            else:\n",
        "                # If adding the new string would exceed the limit, start a new string\n",
        "                result.append(current_string)\n",
        "                current_string = string\n",
        "        else:\n",
        "            # If the new string itself is longer than the limit, split it into chunks\n",
        "            for i in range(0, len(string), max_length):\n",
        "                result.append(string[i:i + max_length])\n",
        "\n",
        "    if current_string:\n",
        "        result.append(current_string)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "IHVz5E97XZEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def read_csv_to_dict(file_path):\n",
        "    data_dict = {}\n",
        "\n",
        "    with open(file_path, mode='r', newline='', encoding='utf-8') as file:\n",
        "        csv_reader = csv.reader(file)\n",
        "\n",
        "        for row in csv_reader:\n",
        "            if len(row) == 2:\n",
        "                key, value = row\n",
        "                data_dict[key] = value\n",
        "\n",
        "    return data_dict\n",
        "\n",
        "# Example usage\n",
        "csv_file_path = folder+'target-length/el.txt'\n",
        "target_sizes = read_csv_to_dict(csv_file_path)\n",
        "print(target_sizes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cEVYE8vYgPE",
        "outputId": "6893dcbe-28a5-4c8e-f1cb-c98670506e70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0218db401253e76a84a568453a7cda5f_body.txt': '1296', '0d86383293996518eee416037c5ff576_body.txt': '1127', '0e697d0ffbed773c79e449f71c4cf9bb_body.txt': '707', '0ed50e7a7058171bf0305aa9ee33dd8d_body.txt': '1174', '15093808572f2be8c394a3acddf7a5e6_body.txt': '1319', '242424914004d4870b483c72b9c949ba_body.txt': '823', '27abeb23b904ec662ac2af636235cf35_body.txt': '1322', '31036d7e299c27bda3b83300ef8d44d6_body.txt': '938', '39f64462c48b3ab3fb053b671104ec2b_body.txt': '1061', '3aa6e4a33f78a86fdd17620156238fca_body.txt': '1218', '3b3d000f9dca943f2bb2c33e31fa33f0_body.txt': '1444', '3ebf88a88c54039d9bf33596b362fa95_body.txt': '891', '430551a29ade3ec53eac2799b6186928_body.txt': '1299', '5a2b3ed3aa2fa2d3cee2fb533fb24111_body.txt': '1114', '5a6c1f722178dc60dbfc9bee0bf3a0b0_body.txt': '1232', '6613e82f5ace4791e571c2f9b8da1e23_body.txt': '953', '6bdaa262298a41f78ede6889521b242c_body.txt': '840', '6e9bfd57cf631d844410e61082b8997d_body.txt': '1188', '7e2e7ed635d9efab20cd0d1decd846ab_body.txt': '1674', '8429d8c60a04adb881680f5c053107ec_body.txt': '994', 'a10110c762cd0d465d43c9836df60a97_body.txt': '1397', 'b9796f9c13e91a28483c8c35389362f6_body.txt': '1102', 'bd95c13ea8b9a21aebdd09342a8c0698_body.txt': '1157', 'c0df147e32b34d36d15a56f3fec08351_body.txt': '917', 'd51ab3cf3b7b10ff54d1071189bfbe10_body.txt': '843', 'd8c5ad89558b8ad5bc0b6cbd3c090bb3_body.txt': '857', 'e0f4f4208dedce2210c89d2eb8f32291_body.txt': '1418', 'e7a9066c2103472d23a0ad4c52f4435b_body.txt': '1254', 'eb1c716cc15dbea7309fd8284265c2d7_body.txt': '1291', 'ee5cba5ab1357bdd87805e5e3832f693_body.txt': '1196'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def doc_length(text_tokens):\n",
        "  length=0\n",
        "  for t in text_tokens:\n",
        "    length+=len(t)\n",
        "  return length\n"
      ],
      "metadata": {
        "id": "3uUC2OE7aVY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GreekSummaries={}\n",
        "body_folder= folder+'body/text/el/'\n",
        "folder_contents = os.listdir(body_folder)\n",
        "for file in folder_contents:\n",
        "  target_length=int(target_sizes[file])\n",
        "  print(target_length)\n",
        "  file_path = body_folder+file\n",
        "  print(file_path)\n",
        "  try:\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "        # Remove newline characters from the end of each line\n",
        "        lines = [line.strip() for line in lines]\n",
        "        print(len(lines))\n",
        "  except FileNotFoundError:\n",
        "      print(f\"File not found: {file_path}\")\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred: {e}\")\n",
        "\n",
        "  preprocessed_lines=[]\n",
        "  for line in lines:\n",
        "    line=line.replace('[Επεξεργασία]','')+' .'\n",
        "    preprocessed_lines.append(line)\n",
        "\n",
        "  # grouped_lines=split_strings_within_limit(preprocessed_lines,100)\n",
        "  # translated_tokens=translator(grouped_lines[0:2])\n",
        "\n",
        "  grouped_lines=split_strings_within_limit(preprocessed_lines,1000)\n",
        "  translated_tokens=translator(grouped_lines)\n",
        "\n",
        "  translations = []\n",
        "  for value in translated_tokens:\n",
        "    print(value)\n",
        "    translations.append(value['translation_text'])\n",
        "  summarized_tokens = summarizer(translations)\n",
        "  print(summarized_tokens)\n",
        "  english_summaries=[]\n",
        "  for value in summarized_tokens:\n",
        "    print(value)\n",
        "    english_summaries.append(value['summary_text'])\n",
        "\n",
        "  english_summaries2=[]\n",
        "  if doc_length(english_summaries)>target_length:\n",
        "    grouped_summary_lines=split_strings_within_limit(english_summaries,target_length)\n",
        "    summarized_tokens2 = summarizer(grouped_summary_lines)\n",
        "    print(summarized_tokens2)\n",
        "    for value in summarized_tokens2:\n",
        "      print(value)\n",
        "      english_summaries2.append(value['summary_text'])\n",
        "\n",
        "\n",
        "  if len(english_summaries2)>0:\n",
        "    greek_sum=retranslator(english_summaries2)\n",
        "  else:\n",
        "    greek_sum=retranslator(english_summaries)\n",
        "\n",
        "  Greek_Summary=''\n",
        "  for value in greek_sum:\n",
        "    Greek_Summary+=value['translation_text']+' '\n",
        "\n",
        "  print(Greek_Summary)\n",
        "  GreekSummaries[file]=Greek_Summary\n",
        "  # break\n"
      ],
      "metadata": {
        "id": "t6csCmpxUiK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GreekSummaries"
      ],
      "metadata": {
        "id": "W5Bnm1LGbhmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(GreekSummaries)"
      ],
      "metadata": {
        "id": "OozNbMUPi2o7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}